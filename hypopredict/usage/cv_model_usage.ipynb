{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcfb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014ac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from hypopredict.cv import CV_splitter\n",
    "from hypopredict import chunker\n",
    "from hypopredict import labeler\n",
    "from hypopredict.params import TRAIN_DAYS\n",
    "\n",
    "from hypopredict.cv import CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455d40cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: there were multiple files for day _21_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-21-12_35_54-1HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-21-20_29_57-1HG.feather']\n",
      "Labeling day 71 with 91 chunks\n",
      "Labeling day 21 with 47 chunks\n",
      "Labeling day 14 with 44 chunks\n",
      "Labeling day 63 with 84 chunks\n",
      "\n",
      "    WARNING: there were multiple files for day _24_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-24-17_43_12-2HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-24-07_01_03-2HG.feather']\n",
      "\n",
      "    WARNING: there were multiple files for day _44_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-44-06_32_58-1HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-44-16_49_30-1HG.feather']\n",
      "\n",
      "    WARNING: there were multiple files for day _61_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-61-15_08_04-0HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-61-06_46_44-0HG.feather']\n",
      "Labeling day 24 with 74 chunks\n",
      "Labeling day 44 with 68 chunks\n",
      "Labeling day 61 with 117 chunks\n",
      "Labeling day 13 with 77 chunks\n",
      "\n",
      "    WARNING: there were multiple files for day _52_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-52-09_23_58-0HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-52-11_40_30-0HG.feather']\n",
      "Labeling day 52 with 82 chunks\n",
      "Labeling day 54 with 45 chunks\n",
      "Labeling day 43 with 49 chunks\n",
      "Labeling day 22 with 80 chunks\n",
      "\n",
      "    WARNING: there were multiple files for day _51_ => there might be a gap in concatinated ecg index so when you check if HG events actually ahppened during recorded ECG times check for this gap\n",
      "    Files concatinated:\n",
      "                 ['/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-51-10_27_42-0HG.feather', '/Users/alexxela/code/hypopredict/data/feathers/EcgWaveform-51-10_40_51-0HG.feather']\n",
      "Labeling day 92 with 87 chunks\n",
      "Labeling day 11 with 74 chunks\n",
      "Labeling day 51 with 71 chunks\n",
      "Labeling day 74 with 83 chunks\n",
      "Labeling day 42 with 74 chunks\n",
      "Labeling day 93 with 71 chunks\n",
      "Labeling day 82 with 104 chunks\n",
      "Labeling day 72 with 66 chunks\n"
     ]
    }
   ],
   "source": [
    "ECG_PATH = os.getenv('ECG_PATH')\n",
    "\n",
    "#######\n",
    "# chunking strategy\n",
    "CHUNK_SIZE = pd.Timedelta(minutes=60)\n",
    "STEP_SIZE = pd.Timedelta(minutes=10)\n",
    "\n",
    "#######\n",
    "# labeling strategy\n",
    "FORECAST_WINDOW = pd.Timedelta(minutes=90)\n",
    "\n",
    "\n",
    "######\n",
    "# rolling features\n",
    "WINDOW_SIZE_FEATURES = pd.Timedelta(minutes=40)\n",
    "STEP_SIZE_FEATURES = pd.Timedelta(minutes=2)\n",
    "\n",
    "\n",
    "# initialize CV splitter\n",
    "splitter = CV_splitter(n_splits = 5,\n",
    "                       ecg_dir = ECG_PATH,\n",
    "                       glucose_src='local',\n",
    "                       random_state = 17)\n",
    "# get splits\n",
    "splits = splitter.get_splits(TRAIN_DAYS)\n",
    "\n",
    "crossval = CrossValidator(splits = splits)\n",
    "\n",
    "splits_prepped = crossval.chunkify_label_stack(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    step_size=STEP_SIZE,\n",
    "    ecg_dir=ECG_PATH,\n",
    "    glucose_src='local',\n",
    "    forecast_window=FORECAST_WINDOW,\n",
    "    roll_window_size=WINDOW_SIZE_FEATURES,\n",
    "    roll_step_size=STEP_SIZE_FEATURES,\n",
    "    suffix=f'roll{WINDOW_SIZE_FEATURES.components.minutes}min',\n",
    "    agg_funcs=['mean', 'std', 'min', 'max', 'median', 'skew', 'kurtosis']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f107c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.0084), np.float64(0.6664), np.float64(0.1801), np.float64(0.1308), np.float64(0.0756)]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(crossval._get_split_mean_labels(splits_prepped))\n",
    "\n",
    "print(type(splits_prepped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40ea874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize XGBoost model\n",
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(\n",
    "    n_estimators=777,\n",
    "    max_depth=5,\n",
    "    reg_lambda=0.1,\n",
    "    learning_rate=0.2,\n",
    "    eval_metric='logloss',\n",
    "    random_state=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d30471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Cross-Validation Iteration: Using split 0 as validation set\n",
      "\n",
      "                        With mean positive class ratio: 0.008\n",
      "\n",
      "                \n",
      "==================================================\n",
      "Resampling training folds [1, 2, 3, 4] \n",
      " to achieve ~0.3 positive class ratio...\n",
      "RESAMPLED\n",
      "Train positive class ratio: 0.381\n",
      "--------------------------------------------------\n",
      "Fitting model on training folds [1, 2, 3, 4]...\n",
      "Evaluating model on training folds [1, 2, 3, 4]...\n",
      "\n",
      "                    TRAIN PR-AUC: 0.6868, Average Precision: 0.3817\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "                  \n",
      "Evaluating model on VALIDATION fold 0...\n",
      "\n",
      "                    VALIDATION PR-AUC: 0.0081, Average Precision: 0.0086\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "\n",
      "\n",
      "                  \n",
      "==================================================\n",
      "Cross-Validation Iteration: Using split 1 as validation set\n",
      "\n",
      "                        With mean positive class ratio: 0.666\n",
      "\n",
      "                \n",
      "==================================================\n",
      "Resampling training folds [0, 2, 3, 4] \n",
      " to achieve ~0.3 positive class ratio...\n",
      "RESAMPLED\n",
      "Train positive class ratio: 0.335\n",
      "--------------------------------------------------\n",
      "Fitting model on training folds [0, 2, 3, 4]...\n",
      "Evaluating model on training folds [0, 2, 3, 4]...\n",
      "\n",
      "                    TRAIN PR-AUC: 1.0000, Average Precision: 1.0000\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "                  \n",
      "Evaluating model on VALIDATION fold 1...\n",
      "\n",
      "                    VALIDATION PR-AUC: 0.4079, Average Precision: 0.6664\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "\n",
      "\n",
      "                  \n",
      "==================================================\n",
      "Cross-Validation Iteration: Using split 2 as validation set\n",
      "\n",
      "                        With mean positive class ratio: 0.180\n",
      "\n",
      "                \n",
      "==================================================\n",
      "Resampling training folds [0, 1, 3, 4] \n",
      " to achieve ~0.3 positive class ratio...\n",
      "RESAMPLED\n",
      "Train positive class ratio: 0.381\n",
      "--------------------------------------------------\n",
      "Fitting model on training folds [0, 1, 3, 4]...\n",
      "Evaluating model on training folds [0, 1, 3, 4]...\n",
      "\n",
      "                    TRAIN PR-AUC: 0.6883, Average Precision: 0.3819\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "                  \n",
      "Evaluating model on VALIDATION fold 2...\n",
      "\n",
      "                    VALIDATION PR-AUC: 0.1750, Average Precision: 0.1772\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "\n",
      "\n",
      "                  \n",
      "==================================================\n",
      "Cross-Validation Iteration: Using split 3 as validation set\n",
      "\n",
      "                        With mean positive class ratio: 0.131\n",
      "\n",
      "                \n",
      "==================================================\n",
      "Resampling training folds [0, 1, 2, 4] \n",
      " to achieve ~0.3 positive class ratio...\n",
      "RESAMPLED\n",
      "Train positive class ratio: 0.381\n",
      "--------------------------------------------------\n",
      "Fitting model on training folds [0, 1, 2, 4]...\n",
      "Evaluating model on training folds [0, 1, 2, 4]...\n",
      "\n",
      "                    TRAIN PR-AUC: 0.6857, Average Precision: 0.3816\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "                  \n",
      "Evaluating model on VALIDATION fold 3...\n",
      "\n",
      "                    VALIDATION PR-AUC: 0.1991, Average Precision: 0.2059\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "\n",
      "\n",
      "                  \n",
      "==================================================\n",
      "Cross-Validation Iteration: Using split 4 as validation set\n",
      "\n",
      "                        With mean positive class ratio: 0.076\n",
      "\n",
      "                \n",
      "==================================================\n",
      "Resampling training folds [0, 1, 2, 3] \n",
      " to achieve ~0.3 positive class ratio...\n",
      "RESAMPLED\n",
      "Train positive class ratio: 0.381\n",
      "--------------------------------------------------\n",
      "Fitting model on training folds [0, 1, 2, 3]...\n",
      "Evaluating model on training folds [0, 1, 2, 3]...\n",
      "\n",
      "                    TRAIN PR-AUC: 0.6851, Average Precision: 0.3817\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "                  \n",
      "Evaluating model on VALIDATION fold 4...\n",
      "\n",
      "                    VALIDATION PR-AUC: 0.1530, Average Precision: 0.1612\n",
      "                \n",
      "\n",
      "                ••••••••••••••••••••••••••••••••••••••••••••••••••••••••\n",
      "\n",
      "\n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "cv_results = crossval.validate_model_cv(model, splits_prepped,\n",
    "                                        resample=True,\n",
    "                                        desired_pos_ratio=0.3,\n",
    "                                        reduction_factor=0.555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f212d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46889999999999993\n",
      "0.21226000000000003\n"
     ]
    }
   ],
   "source": [
    "# looks like it's kind of learning\n",
    "print(np.mean(cv_results['val_pr_aucs']))\n",
    "# 2.25x better than random chance\n",
    "print(np.mean(crossval._get_split_mean_labels(splits_prepped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61276222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34750000000000003\n",
      "[np.float64(0.0084), np.float64(0.6664)]\n",
      "0.3374\n"
     ]
    }
   ],
   "source": [
    "# however the first 2 splits have crazy imbalances with different directioons\n",
    "# that confuses our model for sure\n",
    "# but even here now it seems to be learning something\n",
    "print(np.mean(cv_results['val_pr_aucs'][:2]))\n",
    "print(crossval._get_split_mean_labels(splits_prepped)[:2])\n",
    "print(np.mean(crossval._get_split_mean_labels(splits_prepped)[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49924999999999997\n",
      "0.12883333333333333\n"
     ]
    }
   ],
   "source": [
    "# on more reasonable classes it is learning!!\n",
    "# more than 4x better than random chance\n",
    "# with really silly features! and silly random resampling!\n",
    "print(np.mean(cv_results['val_pr_aucs'][2:]))\n",
    "print(np.mean(crossval._get_split_mean_labels(splits_prepped)[2:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypopredict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
